{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "# load dataset\n",
    "data = pd.read_csv('Actual_Data.csv')\n",
    "\n",
    "# identify numerical and categorical columns\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# calculate priors\n",
    "num_anomalies = sum(data['class'] == 'anomaly')\n",
    "num_no_anomalies = sum(data['class'] == 'normal')\n",
    "total = len(data)\n",
    "\n",
    "priors = {\n",
    "    'anomaly': num_anomalies / total,\n",
    "    'normal': num_no_anomalies / total\n",
    "}\n",
    "\n",
    "# fit PDFs for numerical columns\n",
    "pdfs = {}\n",
    "for feature in numerical_columns:\n",
    "    anomaly_data = data[data['class'] == 'anomaly'][feature]\n",
    "    no_anomaly_data = data[data['class'] == 'normal'][feature]\n",
    "\n",
    "    # compute mean and standard deviation\n",
    "    anomaly_mean = anomaly_data.mean()\n",
    "    anomaly_std = anomaly_data.std()\n",
    "    no_anomaly_mean = no_anomaly_data.mean()\n",
    "    no_anomaly_std = no_anomaly_data.std()\n",
    "\n",
    "    # handle zero standard deviation\n",
    "    anomaly_std = anomaly_std if anomaly_std > 0 else 1e-6  # Replace 0 with a small value\n",
    "    no_anomaly_std = no_anomaly_std if no_anomaly_std > 0 else 1e-6  # Replace 0 with a small value\n",
    "\n",
    "    # store the PDFs\n",
    "    pdfs[feature] = {\n",
    "        'anomaly': norm(loc=anomaly_mean, scale=anomaly_std),\n",
    "        'normal': norm(loc=no_anomaly_mean, scale=no_anomaly_std)\n",
    "    }\n",
    "\n",
    "# fit PMFs for categorical columns\n",
    "pmfs = {}\n",
    "for feature in categorical_columns:\n",
    "    anomaly_counts = data[data['class'] == 'anomaly'][feature].value_counts(normalize=True)\n",
    "    no_anomaly_counts = data[data['class'] == 'normal'][feature].value_counts(normalize=True)\n",
    "\n",
    "    pmfs[feature] = {\n",
    "        'anomaly': anomaly_counts.to_dict(),\n",
    "        'normal': no_anomaly_counts.to_dict()\n",
    "    }\n",
    "\n",
    "# extract features and target\n",
    "X_categorical = data[categorical_columns]\n",
    "X_numerical = data[numerical_columns]\n",
    "y = data['class']\n",
    "\n",
    "# convert data to NumPy arrays for faster processing\n",
    "numerical_data = data[numerical_columns].to_numpy()\n",
    "categorical_data = data[categorical_columns].to_numpy()\n",
    "target = data['class'].to_numpy()\n",
    "\n",
    "# precompute log priors\n",
    "log_priors = {\n",
    "    'anomaly': np.log(priors['anomaly']),\n",
    "    'normal': np.log(priors['normal'])\n",
    "}\n",
    "\n",
    "# precompute log PDFs for numerical features\n",
    "log_pdfs = {}\n",
    "for feature in numerical_columns:\n",
    "    anomaly_data = data[data['class'] == 'anomaly'][feature]\n",
    "    no_anomaly_data = data[data['class'] == 'normal'][feature]\n",
    "\n",
    "    anomaly_mean = anomaly_data.mean()\n",
    "    anomaly_std = anomaly_data.std() if anomaly_data.std() > 0 else 1e-6\n",
    "    no_anomaly_mean = no_anomaly_data.mean()\n",
    "    no_anomaly_std = no_anomaly_data.std() if no_anomaly_data.std() > 0 else 1e-6\n",
    "\n",
    "    log_pdfs[feature] = {\n",
    "        'anomaly': norm(loc=anomaly_mean, scale=anomaly_std).logpdf(numerical_data[:, numerical_columns.get_loc(feature)]),\n",
    "        'normal': norm(loc=no_anomaly_mean, scale=no_anomaly_std).logpdf(numerical_data[:, numerical_columns.get_loc(feature)])\n",
    "    }\n",
    "\n",
    "# precompute log PMFs for categorical features\n",
    "log_pmfs = {}\n",
    "for idx, feature in enumerate(categorical_columns):\n",
    "    anomaly_counts = data[data['class'] == 'anomaly'][feature].value_counts(normalize=True)\n",
    "    no_anomaly_counts = data[data['class'] == 'normal'][feature].value_counts(normalize=True)\n",
    "\n",
    "    log_pmfs[feature] = {\n",
    "        'anomaly': {k: np.log(v) for k, v in anomaly_counts.items()},\n",
    "        'normal': {k: np.log(v) for k, v in no_anomaly_counts.items()}\n",
    "    }\n",
    "\n",
    "# calculate probabilities using vectorized operations\n",
    "def calculate_probabilities_vectorized(numerical_data, categorical_data):\n",
    "    log_anomaly_prob = np.full(len(data), log_priors['anomaly'])\n",
    "    log_normal_prob = np.full(len(data), log_priors['normal'])\n",
    "\n",
    "    # add numerical contributions\n",
    "    for idx, feature in enumerate(numerical_columns):\n",
    "        log_anomaly_prob += log_pdfs[feature]['anomaly']\n",
    "        log_normal_prob += log_pdfs[feature]['normal']\n",
    "\n",
    "    # add categorical contributions\n",
    "    for idx, feature in enumerate(categorical_columns):\n",
    "        for i, value in enumerate(categorical_data[:, idx]):\n",
    "            log_anomaly_prob[i] += log_pmfs[feature]['anomaly'].get(value, -np.inf)\n",
    "            log_normal_prob[i] += log_pmfs[feature]['normal'].get(value, -np.inf)\n",
    "\n",
    "    # convert log probabilities to normal probabilities\n",
    "    anomaly_prob = np.exp(log_anomaly_prob)\n",
    "    normal_prob = np.exp(log_normal_prob)\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    total_prob = anomaly_prob + normal_prob + epsilon # to prevent zero denominators\n",
    "    return anomaly_prob / total_prob, normal_prob / total_prob\n",
    "\n",
    "# vectorized prediction\n",
    "anomaly_probs, normal_probs = calculate_probabilities_vectorized(numerical_data, categorical_data)\n",
    "predictions = np.where(anomaly_probs > normal_probs, 'anomaly', 'normal')\n",
    "\n",
    "# calculate metrics for the manual implementation\n",
    "accuracy = accuracy_score(target, predictions)\n",
    "precision = precision_score(target, predictions, pos_label='anomaly')\n",
    "recall = recall_score(target, predictions, pos_label='anomaly')\n",
    "\n",
    "print(\"Manual Na誰ve Bayes Model (Optimized)\")\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "# # probability calculation function\n",
    "# def calculate_probabilities(row, priors, pdfs, pmfs):\n",
    "#     anomaly_log_sum = np.log(priors['anomaly'])\n",
    "#     normal_log_sum = np.log(priors['normal'])\n",
    "#\n",
    "#     for feature, value in row.items():\n",
    "#         if feature in pdfs:  # Numerical features\n",
    "#             anomaly_pdf = pdfs[feature]['anomaly'].pdf(value)\n",
    "#             normal_pdf = pdfs[feature]['normal'].pdf(value)\n",
    "#\n",
    "#             if anomaly_pdf > 0:\n",
    "#                 anomaly_log_sum += np.log(anomaly_pdf)\n",
    "#             if normal_pdf > 0:\n",
    "#                 normal_log_sum += np.log(normal_pdf)\n",
    "#         elif feature in pmfs:  # Categorical features\n",
    "#             anomaly_pmf = pmfs[feature]['anomaly'].get(value, 0)\n",
    "#             normal_pmf = pmfs[feature]['normal'].get(value, 0)\n",
    "#\n",
    "#             if anomaly_pmf > 0:\n",
    "#                 anomaly_log_sum += np.log(anomaly_pmf)\n",
    "#             if normal_pmf > 0:\n",
    "#                 normal_log_sum += np.log(normal_pmf)\n",
    "#\n",
    "#     # Convert log-probabilities back to normal probabilities\n",
    "#     anomaly_prob = np.exp(anomaly_log_sum)\n",
    "#     normal_prob = np.exp(normal_log_sum)\n",
    "#\n",
    "#     denominator = anomaly_prob + normal_prob\n",
    "#     if denominator == 0 or np.isnan(denominator):\n",
    "#         return 0.5, 0.5  # Fallback to equal probabilities\n",
    "#\n",
    "#     return anomaly_prob / denominator, normal_prob / denominator\n",
    "\n",
    "# # evaluate model\n",
    "# predictions = []\n",
    "# for _, row in data.iterrows():\n",
    "#     row_dict = row.to_dict()\n",
    "#     pr_anomaly, pr_no_anomaly = calculate_probabilities(row_dict, priors, pdfs, pmfs)\n",
    "#     predicted_label = 'anomaly' if pr_anomaly > pr_no_anomaly else 'normal'\n",
    "#     predictions.append(predicted_label)\n",
    "#\n",
    "# # calculate metrics for the manual implementation\n",
    "# accuracy = accuracy_score(y, predictions)\n",
    "# precision = precision_score(y, predictions, pos_label='anomaly')\n",
    "# recall = recall_score(y, predictions, pos_label='anomaly')\n",
    "#\n",
    "# print(\"Manual Na誰ve Bayes Model\")\n",
    "# print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6e3ef8576cbacc1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# one-Hot Encoding for categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Ensure dense output\n",
    "X_encoded = encoder.fit_transform(X_categorical)\n",
    "\n",
    "# combine encoded categorical features with numerical features\n",
    "X_combined = np.hstack([X_encoded, X_numerical])\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# train and evaluate Na誰ve Bayes models\n",
    "models = {\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"BernoulliNB\": BernoulliNB()\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, pos_label='anomaly'),\n",
    "        \"recall\": recall_score(y_test, y_pred, pos_label='anomaly')\n",
    "    }\n",
    "\n",
    "# display results\n",
    "print(\"\\nScikit-Learn Na誰ve Bayes Models\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"{model}: Accuracy={metrics['accuracy']}, Precision={metrics['precision']}, Recall={metrics['recall']}\")\n"
   ],
   "id": "ca6ac4a80b08278a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63bca67a945f59f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
